# U-Net 模型改进说明

## 改进时间
2025年10月29日

## 备份文件
- `CTAI_flask/core/net/unet_backup.py` - Flask 后端原始模型
- `CTAI_model/net/unet_backup.py` - 训练模块原始模型

## 改进内容

### 1. 添加注意力门控机制 (Attention Gate)

**核心思想**：  
在 U-Net 的跳跃连接处添加注意力门控，让模型自动学习关注肿瘤区域，抑制背景噪声。

**实现位置**：
- 在每个上采样后的特征融合前，对编码器特征应用注意力加权
- 4 个注意力门控分别位于 up6、up7、up8、up9 之后

**技术细节**：
```
AttentionGate(F_g=512, F_l=512, F_int=256)  # 第1层
AttentionGate(F_g=256, F_l=256, F_int=128)  # 第2层
AttentionGate(F_g=128, F_l=128, F_int=64)   # 第3层
AttentionGate(F_g=64, F_l=64, F_int=32)     # 第4层
```

**预期效果**：
- 分割精度提升 2-5%
- 减少假阳性（背景误检）
- 参数增加量 < 5%
- 推理速度几乎无影响

## 使用说明

### 兼容性
改进后的模型与原始接口完全兼容：
- 输入输出维度不变
- 函数调用方式不变
- 可直接替换使用

### 重新训练（可选）
如果需要重新训练模型以发挥注意力机制的全部效果：

1. 进入训练目录：
```powershell
cd CTAI_model/net
```

2. 运行训练脚本：
```powershell
python train.py
```

3. 训练完成后，将新的 `model.pth` 复制到：
```
CTAI_flask/core/net/model.pth
```

### 直接使用
如果已有训练好的权重文件，可以直接加载：
- 注意力模块会从随机初始化开始
- 原有卷积层权重保持不变
- 可能需要微调(fine-tune)以达到最佳效果Transformer 融合

## 恢复原始版本

如果需要恢复到原始 U-Net：

```powershell
# 恢复 Flask 后端
Copy-Item "CTAI_flask\core\net\unet_backup.py" "CTAI_flask\core\net\unet.py" -Force

# 恢复训练模块
Copy-Item "CTAI_model\net\unet_backup.py" "CTAI_model\net\unet.py" -Force
```

## 进一步改进方向

如果当前改进效果良好，可以考虑：
1. **损失函数优化**：Dice Loss + Focal Loss 组合
2. **残差连接**：将 DoubleConv 改为 ResBlock
3. **多尺度融合**：在瓶颈层添加 ASPP 模块
4. **数据增强**：添加更多的旋转、翻转、弹性形变

## 参考文献
- Attention U-Net: Learning Where to Look for the Pancreas (2018)
- Medical Image Segmentation using Deep Learning: A Survey (2020)
