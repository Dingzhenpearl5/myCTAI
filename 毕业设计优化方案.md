# åŸºäº Transformer-UNet èåˆçš„ç›´è‚ è‚¿ç˜¤è¾…åŠ©è¯Šæ–­ç³»ç»Ÿ - æ¯•ä¸šè®¾è®¡ä¼˜åŒ–æ–¹æ¡ˆ

## é¡¹ç›®å®šä½
**é¢˜ç›®ï¼š** åŸºäºæ·±åº¦å­¦ä¹ çš„ç›´è‚ è‚¿ç˜¤ CT å›¾åƒæ™ºèƒ½åˆ†å‰²ç³»ç»Ÿ  
**æ ¸å¿ƒåˆ›æ–°ï¼š** Transformer + UNet èåˆæ¶æ„ + æ³¨æ„åŠ›æœºåˆ¶  
**åº”ç”¨ä»·å€¼ï¼š** è¾…åŠ©åŒ»ç”Ÿè¯Šæ–­ï¼Œæé«˜è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§

---

## å½“å‰é¡¹ç›®çŠ¶æ€

### âœ… å·²å®Œæˆéƒ¨åˆ†
- **åŸºç¡€ U-Net æ¶æ„** - å¸¦ Attention Gate
- **è®­ç»ƒæ¡†æ¶** - PyTorch,Dice Loss + BCE Loss,å­¦ä¹ ç‡è°ƒåº¦,æ—©åœ
- **æ•°æ®é›†** - 107 æ‚£è€…,6:2:2æ‚£è€…çº§åˆ«åˆ’åˆ† (503è®­ç»ƒ/173éªŒè¯/184æµ‹è¯•)
- **æ€§èƒ½æŒ‡æ ‡** - **Dice 78.02%** (ä¿®å¤æ•°æ®æ³„éœ²åçš„çœŸå®åŸºçº¿)
- **å‰åç«¯** - Flask åç«¯ + Vue å‰ç«¯
- **åŸºæœ¬åŠŸèƒ½** - DICOM ä¸Šä¼ ã€é¢„å¤„ç†ã€æ¨¡å‹æ¨ç†ã€ç»“æœå±•ç¤º
- **æ•°æ®æ³„éœ²ä¿®å¤** - æ‚£è€…çº§åˆ«éšæœºåˆ’åˆ†,æ— æ•°æ®æ³„éœ²

### âš ï¸ éœ€è¦ä¼˜åŒ–éƒ¨åˆ†
1. **æ¨¡å‹æ¶æ„** - éœ€ä»UNetå‡çº§åˆ°TransUNet (å·²å®ç°ä»£ç )
2. **æ€§èƒ½æå‡** - ä»78.02%æå‡åˆ°83-88%
3. **è¯„ä¼°æŒ‡æ ‡** - ä»… Diceï¼Œç¼ºå°‘å…¶ä»–åŒ»å­¦æŒ‡æ ‡
4. **ç³»ç»ŸåŠŸèƒ½** - ç¼ºå°‘æ•°æ®åº“ã€ç”¨æˆ·ç®¡ç†ã€å†å²è®°å½•
5. **å¯è§†åŒ–** - åˆ†å‰²ç»“æœå¯è§†åŒ–ä¸å¤Ÿç›´è§‚
6. **éƒ¨ç½²** - æœªè€ƒè™‘ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

---

## æ¯•ä¸šè®¾è®¡ä¼˜åŒ–è·¯çº¿å›¾

### ğŸ¯ æ ¸å¿ƒç›®æ ‡
1. **å®ç° TransUNet æ¶æ„** - èåˆ Transformer å’Œ UNet
2. **æå‡æ¨¡å‹æ€§èƒ½** - Dice è¾¾åˆ° 80%+
3. **å®Œå–„ç³»ç»ŸåŠŸèƒ½** - æ•°æ®åº“ã€ç”¨æˆ·ç®¡ç†ã€å†å²å¯¹æ¯”
4. **ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ** - å¯è§†åŒ–ã€äº¤äº’ã€æŠ¥å‘Šç”Ÿæˆ
5. **æ’°å†™æ¯•ä¸šè®ºæ–‡** - ç†è®ºåŸºç¡€ã€å®éªŒåˆ†æã€ç³»ç»Ÿè®¾è®¡

---

## ä¸€ã€æ¨¡å‹æ¶æ„ä¼˜åŒ– (æ ¸å¿ƒåˆ›æ–°ç‚¹)

### 1.1 TransUNet æ¶æ„è®¾è®¡

#### **æ–¹æ¡ˆï¼šTransformer Encoder + UNet Decoder**

```
è¾“å…¥ CT å›¾åƒ (512Ã—512)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patch Embedding                 â”‚
â”‚  - å°†å›¾åƒåˆ†å‰²ä¸º 16Ã—16 patches     â”‚
â”‚  - è¾“å‡º: (32Ã—32, 768)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer Encoder (12 å±‚)     â”‚
â”‚  - Multi-Head Self-Attention    â”‚
â”‚  - Feed-Forward Network          â”‚
â”‚  - Layer Normalization           â”‚
â”‚  - æå–å…¨å±€è¯­ä¹‰ç‰¹å¾               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hybrid Decoder                  â”‚
â”‚  - CNN Decoder (UNet é£æ ¼)       â”‚
â”‚  - Skip Connection (èåˆç¼–ç ç‰¹å¾) â”‚
â”‚  - Attention Gate                â”‚
â”‚  - ä¸Šé‡‡æ ·è¿˜åŸåˆ†è¾¨ç‡                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    è¾“å‡ºåˆ†å‰² Mask (512Ã—512)
```

#### **å…³é”®ä»£ç æ¡†æ¶ï¼š**

```python
# CTAI_model/net/transunet.py
import torch
import torch.nn as nn
from timm.models import vision_transformer as vit

class TransUNet(nn.Module):
    def __init__(self, img_size=512, patch_size=16, num_classes=1):
        super().__init__()
        
        # 1. Transformer Encoder (ä½¿ç”¨ ViT-Base)
        self.transformer = vit.VisionTransformer(
            img_size=img_size,
            patch_size=patch_size,
            embed_dim=768,
            depth=12,
            num_heads=12,
            num_classes=0  # ä¸ä½¿ç”¨åˆ†ç±»å¤´
        )
        
        # 2. CNN Encoder (ä½å±‚ç‰¹å¾æå–)
        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        
        # 3. Hybrid Decoder (èåˆ Transformer å’Œ CNN ç‰¹å¾)
        self.decoder4 = DecoderBlock(768, 512)  # Transformer ç‰¹å¾
        self.decoder3 = DecoderBlock(512, 256)
        self.decoder2 = DecoderBlock(256, 128)
        self.decoder1 = DecoderBlock(128, 64)
        
        # 4. Attention Gates (è·³è·ƒè¿æ¥æ³¨æ„åŠ›)
        self.att3 = AttentionGate(256, 256, 128)
        self.att2 = AttentionGate(128, 128, 64)
        self.att1 = AttentionGate(64, 64, 32)
        
        # 5. è¾“å‡ºå±‚
        self.final = nn.Sequential(
            nn.Conv2d(64, num_classes, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # CNN ç¼–ç å™¨ (æå–å¤šå°ºåº¦ç‰¹å¾)
        c1 = self.conv1(x)  # 64, 512, 512
        c2 = self.conv2(F.max_pool2d(c1, 2))  # 128, 256, 256
        c3 = self.conv3(F.max_pool2d(c2, 2))  # 256, 128, 128
        
        # Transformer ç¼–ç å™¨ (å…¨å±€è¯­ä¹‰)
        t_features = self.transformer.forward_features(x)  # (B, 1024, 768)
        t_features = t_features.view(B, 32, 32, 768).permute(0, 3, 1, 2)  # (B, 768, 32, 32)
        
        # Hybrid è§£ç å™¨ (èåˆç‰¹å¾)
        d4 = self.decoder4(t_features)  # 512, 64, 64
        
        c3_att = self.att3(d4, c3)  # æ³¨æ„åŠ›èåˆ
        d3 = self.decoder3(torch.cat([d4, c3_att], dim=1))  # 256, 128, 128
        
        c2_att = self.att2(d3, c2)
        d2 = self.decoder2(torch.cat([d3, c2_att], dim=1))  # 128, 256, 256
        
        c1_att = self.att1(d2, c1)
        d1 = self.decoder1(torch.cat([d2, c1_att], dim=1))  # 64, 512, 512
        
        out = self.final(d1)
        return out

class DecoderBlock(nn.Module):
    """ä¸Šé‡‡æ ·è§£ç å—"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.upsample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.conv = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        x = self.upsample(x)
        x = self.conv(x)
        return x
```

#### **ä¼˜åŠ¿åˆ†æï¼š**
1. **å…¨å±€æ„Ÿå—é‡** - Transformer æ•è·é•¿è·ç¦»ä¾èµ–
2. **å¤šå°ºåº¦ç‰¹å¾** - CNN æå–å±€éƒ¨ç»†èŠ‚
3. **æ³¨æ„åŠ›èåˆ** - Attention Gate ä¼˜åŒ–è·³è·ƒè¿æ¥
4. **é€‚åº”å°ç›®æ ‡** - è‚¿ç˜¤å æ¯”ä»… 0.5%ï¼ŒTransformer æ“…é•¿æ­¤åœºæ™¯

---

### 1.2 åŒåˆ†æ”¯æ³¨æ„åŠ›æ¨¡å— (å¯é€‰åˆ›æ–°ç‚¹)

```python
class DualAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ› + é€šé“æ³¨æ„åŠ›"""
    def __init__(self, channels):
        super().__init__()
        # é€šé“æ³¨æ„åŠ›
        self.channel_att = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, channels//16, 1),
            nn.ReLU(),
            nn.Conv2d(channels//16, channels, 1),
            nn.Sigmoid()
        )
        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_att = nn.Sequential(
            nn.Conv2d(2, 1, 7, padding=3),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # é€šé“æ³¨æ„åŠ›
        c_att = self.channel_att(x)
        x = x * c_att
        
        # ç©ºé—´æ³¨æ„åŠ›
        avg_pool = torch.mean(x, dim=1, keepdim=True)
        max_pool, _ = torch.max(x, dim=1, keepdim=True)
        s_att = self.spatial_att(torch.cat([avg_pool, max_pool], dim=1))
        x = x * s_att
        
        return x
```

---

## äºŒã€è®­ç»ƒç­–ç•¥ä¼˜åŒ–

### 2.1 å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

```python
# CTAI_model/net/train.py

# æ–¹æ¡ˆ 1: Cosine Annealing (æ¨è)
from torch.optim.lr_scheduler import CosineAnnealingLR

scheduler = CosineAnnealingLR(
    optimizer, 
    T_max=50,      # æ€» epochs
    eta_min=1e-6   # æœ€å°å­¦ä¹ ç‡
)

# æ–¹æ¡ˆ 2: åˆ†æ®µè¡°å‡
from torch.optim.lr_scheduler import MultiStepLR

scheduler = MultiStepLR(
    optimizer,
    milestones=[20, 35, 45],  # åœ¨è¿™äº› epoch é™ä½å­¦ä¹ ç‡
    gamma=0.1                  # è¡°å‡å› å­
)

# æ–¹æ¡ˆ 3: ReduceLROnPlateau (æ ¹æ®æ€§èƒ½è‡ªé€‚åº”)
from torch.optim.lr_scheduler import ReduceLROnPlateau

scheduler = ReduceLROnPlateau(
    optimizer,
    mode='max',           # ç›‘æ§ Dice (è¶Šå¤§è¶Šå¥½)
    factor=0.5,           # è¡°å‡å› å­
    patience=5,           # 5 ä¸ª epoch æ— æå‡åˆ™é™ä½
    verbose=True
)

# è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
for epoch in range(epochs):
    train_loss, train_dice = train_one_epoch()
    test_dice = test()
    
    # æ–¹æ¡ˆ 1 & 2
    scheduler.step()
    
    # æ–¹æ¡ˆ 3
    scheduler.step(test_dice)
    
    print(f"Epoch {epoch}, LR: {optimizer.param_groups[0]['lr']:.6f}")
```

### 2.2 æ•°æ®å¢å¼º

```python
# CTAI_model/utils/augmentation.py
import albumentations as A
from albumentations.pytorch import ToTensorV2

train_transform = A.Compose([
    # å‡ ä½•å˜æ¢
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.3),
    A.Rotate(limit=15, p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),
    
    # å¼ºåº¦å˜æ¢
    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
    
    # å¼¹æ€§å˜å½¢ (æ¨¡æ‹Ÿå™¨å®˜å˜å½¢)
    A.ElasticTransform(alpha=50, sigma=10, p=0.3),
    
    # å½’ä¸€åŒ–
    A.Normalize(mean=0.0, std=1.0),
    ToTensorV2()
], additional_targets={'mask': 'mask'})

# åœ¨ Dataset ä¸­ä½¿ç”¨
class CTDataset(Dataset):
    def __init__(self, data_path, transform=None):
        self.transform = transform
        # ...
    
    def __getitem__(self, idx):
        image, mask = self.load_data(idx)
        
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']
        
        return image, mask
```

### 2.3 æ··åˆç²¾åº¦è®­ç»ƒ (åŠ é€Ÿ 30-50%)

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

def train():
    for x, y in dataloaders:
        x = x.to(device)
        y = y.to(device)
        
        optimizer.zero_grad()
        
        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast():
            outputs = model(x)
            loss_bce = criterion_bce(outputs, y)
            loss_dice = dice_loss_fn(outputs, y)
            loss = loss_bce + loss_dice
        
        # æ··åˆç²¾åº¦åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
```

### 2.4 Early Stopping

```python
class EarlyStopping:
    def __init__(self, patience=10, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_dice = 0
        self.early_stop = False
    
    def __call__(self, dice):
        if dice < self.best_dice + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_dice = dice
            self.counter = 0
        
        return self.early_stop

# ä½¿ç”¨
early_stopping = EarlyStopping(patience=10)

for epoch in range(epochs):
    train_dice = train()
    test_dice = test()
    
    if early_stopping(test_dice):
        print(f"Early stopping at epoch {epoch}")
        break
```

---

## ä¸‰ã€è¯„ä¼°æŒ‡æ ‡æ‰©å±•

### 3.1 å¤šç»´åº¦è¯„ä¼°ä½“ç³»

```python
# CTAI_model/utils/metrics.py
import numpy as np

class MedicalMetrics:
    """åŒ»å­¦å›¾åƒåˆ†å‰²è¯„ä¼°æŒ‡æ ‡"""
    
    @staticmethod
    def dice_coefficient(pred, target, smooth=1e-5):
        """Dice ç³»æ•° (F1-Score)"""
        intersection = (pred * target).sum()
        return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    
    @staticmethod
    def iou(pred, target, smooth=1e-5):
        """IoU (Jaccard Index)"""
        intersection = (pred * target).sum()
        union = pred.sum() + target.sum() - intersection
        return (intersection + smooth) / (union + smooth)
    
    @staticmethod
    def sensitivity(pred, target, smooth=1e-5):
        """çµæ•åº¦ (å¬å›ç‡) - è‚¿ç˜¤æ£€å‡ºç‡"""
        tp = (pred * target).sum()
        fn = ((1 - pred) * target).sum()
        return (tp + smooth) / (tp + fn + smooth)
    
    @staticmethod
    def specificity(pred, target, smooth=1e-5):
        """ç‰¹å¼‚åº¦ - éè‚¿ç˜¤åŒºåŸŸå‡†ç¡®ç‡"""
        tn = ((1 - pred) * (1 - target)).sum()
        fp = (pred * (1 - target)).sum()
        return (tn + smooth) / (tn + fp + smooth)
    
    @staticmethod
    def precision(pred, target, smooth=1e-5):
        """ç²¾ç¡®åº¦ - é¢„æµ‹ä¸ºè‚¿ç˜¤çš„å‡†ç¡®æ€§"""
        tp = (pred * target).sum()
        fp = (pred * (1 - target)).sum()
        return (tp + smooth) / (tp + fp + smooth)
    
    @staticmethod
    def hausdorff_distance(pred, target):
        """Hausdorff è·ç¦» - è¾¹ç•Œç²¾åº¦"""
        from scipy.spatial.distance import directed_hausdorff
        pred_points = np.argwhere(pred)
        target_points = np.argwhere(target)
        if len(pred_points) == 0 or len(target_points) == 0:
            return float('inf')
        return max(
            directed_hausdorff(pred_points, target_points)[0],
            directed_hausdorff(target_points, pred_points)[0]
        )
    
    @staticmethod
    def volume_error(pred, target):
        """ä½“ç§¯è¯¯å·® - è‚¿ç˜¤å¤§å°ä¼°è®¡å‡†ç¡®æ€§"""
        pred_volume = pred.sum()
        target_volume = target.sum()
        return abs(pred_volume - target_volume) / target_volume

# ä½¿ç”¨ç¤ºä¾‹
def evaluate_model(model, dataloader):
    metrics = MedicalMetrics()
    results = {
        'dice': [], 'iou': [], 'sensitivity': [], 
        'specificity': [], 'precision': [], 'hausdorff': []
    }
    
    for x, y in dataloader:
        pred = model(x) > 0.5
        
        results['dice'].append(metrics.dice_coefficient(pred, y))
        results['iou'].append(metrics.iou(pred, y))
        results['sensitivity'].append(metrics.sensitivity(pred, y))
        results['specificity'].append(metrics.specificity(pred, y))
        results['precision'].append(metrics.precision(pred, y))
        results['hausdorff'].append(metrics.hausdorff_distance(pred, y))
    
    return {k: np.mean(v) for k, v in results.items()}
```

### 3.2 è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

```python
def generate_evaluation_report(results, save_path='evaluation_report.md'):
    """ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š"""
    report = f"""
# æ¨¡å‹è¯„ä¼°æŠ¥å‘Š

## æ•´ä½“æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | æ ‡å‡† | è¯„çº§ |
|------|------|------|------|
| **Dice ç³»æ•°** | {results['dice']:.4f} | > 0.80 | {'âœ… ä¼˜ç§€' if results['dice'] > 0.8 else 'âš ï¸ è‰¯å¥½'} |
| **IoU** | {results['iou']:.4f} | > 0.70 | {'âœ… ä¼˜ç§€' if results['iou'] > 0.7 else 'âš ï¸ è‰¯å¥½'} |
| **çµæ•åº¦ (Sensitivity)** | {results['sensitivity']:.4f} | > 0.85 | {'âœ… ä¼˜ç§€' if results['sensitivity'] > 0.85 else 'âš ï¸ è‰¯å¥½'} |
| **ç‰¹å¼‚åº¦ (Specificity)** | {results['specificity']:.4f} | > 0.95 | {'âœ… ä¼˜ç§€' if results['specificity'] > 0.95 else 'âš ï¸ è‰¯å¥½'} |
| **ç²¾ç¡®åº¦ (Precision)** | {results['precision']:.4f} | > 0.80 | {'âœ… ä¼˜ç§€' if results['precision'] > 0.8 else 'âš ï¸ è‰¯å¥½'} |
| **Hausdorff è·ç¦»** | {results['hausdorff']:.2f} px | < 10 | {'âœ… ä¼˜ç§€' if results['hausdorff'] < 10 else 'âš ï¸ è‰¯å¥½'} |

## ä¸´åºŠæ„ä¹‰

- **çµæ•åº¦ {results['sensitivity']:.2%}**: æ„å‘³ç€èƒ½æ£€å‡º {results['sensitivity']:.2%} çš„è‚¿ç˜¤ç—…ç¶
- **ç‰¹å¼‚åº¦ {results['specificity']:.2%}**: æ„å‘³ç€ {results['specificity']:.2%} çš„éè‚¿ç˜¤åŒºåŸŸè¢«æ­£ç¡®è¯†åˆ«
- **ç²¾ç¡®åº¦ {results['precision']:.2%}**: æ¨¡å‹æ ‡è®°ä¸ºè‚¿ç˜¤çš„åŒºåŸŸä¸­ï¼Œ{results['precision']:.2%} æ˜¯çœŸå®è‚¿ç˜¤
"""
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    return report
```

---

## å››ã€ç³»ç»ŸåŠŸèƒ½å®Œå–„

### 4.1 æ•°æ®åº“è®¾è®¡ (MySQL)

```sql
-- database_schema.sql

-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id INT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    email VARCHAR(100),
    role ENUM('admin', 'doctor', 'viewer') DEFAULT 'doctor',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ‚£è€…ä¿¡æ¯è¡¨
CREATE TABLE patients (
    id INT PRIMARY KEY AUTO_INCREMENT,
    patient_id VARCHAR(50) UNIQUE NOT NULL,
    name VARCHAR(100),
    age INT,
    gender ENUM('M', 'F', 'O'),
    medical_record_number VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- DICOM æ–‡ä»¶è¡¨
CREATE TABLE dicom_files (
    id INT PRIMARY KEY AUTO_INCREMENT,
    patient_id INT,
    file_path VARCHAR(500) NOT NULL,
    file_hash VARCHAR(64),  -- SHA256
    upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    series_uid VARCHAR(100),
    modality VARCHAR(10),
    FOREIGN KEY (patient_id) REFERENCES patients(id)
);

-- è¯Šæ–­è®°å½•è¡¨
CREATE TABLE diagnoses (
    id INT PRIMARY KEY AUTO_INCREMENT,
    patient_id INT,
    dicom_file_id INT,
    user_id INT,  -- æ“ä½œåŒ»ç”Ÿ
    model_version VARCHAR(50),
    dice_score FLOAT,
    iou FLOAT,
    sensitivity FLOAT,
    specificity FLOAT,
    tumor_volume FLOAT,  -- è‚¿ç˜¤ä½“ç§¯ (åƒç´ æ•°)
    mask_path VARCHAR(500),  -- åˆ†å‰²ç»“æœè·¯å¾„
    confidence FLOAT,  -- æ¨¡å‹ç½®ä¿¡åº¦
    diagnosis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    reviewed BOOLEAN DEFAULT FALSE,
    reviewer_id INT,  -- å®¡æ ¸åŒ»ç”Ÿ
    review_comment TEXT,
    FOREIGN KEY (patient_id) REFERENCES patients(id),
    FOREIGN KEY (dicom_file_id) REFERENCES dicom_files(id),
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- æ¨¡å‹ç‰ˆæœ¬è¡¨
CREATE TABLE model_versions (
    id INT PRIMARY KEY AUTO_INCREMENT,
    version VARCHAR(50) NOT NULL,
    architecture VARCHAR(100),
    parameters TEXT,  -- JSON
    training_data VARCHAR(500),
    dice_score FLOAT,
    deployment_date TIMESTAMP,
    is_active BOOLEAN DEFAULT FALSE
);

-- å®¡è®¡æ—¥å¿—è¡¨
CREATE TABLE audit_logs (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT,
    action VARCHAR(100),
    resource_type VARCHAR(50),
    resource_id INT,
    details TEXT,
    ip_address VARCHAR(45),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

### 4.2 åç«¯ API æ‰©å±• (Flask)

```python
# CTAI_flask/app.py
from flask import Flask, request, jsonify
from flask_sqlalchemy import SQLAlchemy
from flask_jwt_extended import JWTManager, create_access_token, jwt_required
from werkzeug.security import generate_password_hash, check_password_hash
import hashlib
from datetime import datetime

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://user:password@localhost/ctai_db'
app.config['JWT_SECRET_KEY'] = 'your-secret-key'

db = SQLAlchemy(app)
jwt = JWTManager(app)

# æ¨¡å‹å®šä¹‰
class User(db.Model):
    __tablename__ = 'users'
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(50), unique=True)
    password_hash = db.Column(db.String(255))
    role = db.Column(db.String(20))

class Patient(db.Model):
    __tablename__ = 'patients'
    id = db.Column(db.Integer, primary_key=True)
    patient_id = db.Column(db.String(50), unique=True)
    name = db.Column(db.String(100))
    age = db.Column(db.Integer)

class Diagnosis(db.Model):
    __tablename__ = 'diagnoses'
    id = db.Column(db.Integer, primary_key=True)
    patient_id = db.Column(db.Integer, db.ForeignKey('patients.id'))
    dice_score = db.Column(db.Float)
    mask_path = db.Column(db.String(500))
    diagnosis_time = db.Column(db.DateTime)

# API è·¯ç”±
@app.route('/api/auth/login', methods=['POST'])
def login():
    """ç”¨æˆ·ç™»å½•"""
    data = request.json
    user = User.query.filter_by(username=data['username']).first()
    
    if user and check_password_hash(user.password_hash, data['password']):
        access_token = create_access_token(identity=user.id)
        return jsonify({
            'token': access_token,
            'username': user.username,
            'role': user.role
        })
    
    return jsonify({'error': 'Invalid credentials'}), 401

@app.route('/api/patients', methods=['GET'])
@jwt_required()
def get_patients():
    """è·å–æ‚£è€…åˆ—è¡¨"""
    patients = Patient.query.all()
    return jsonify([{
        'id': p.id,
        'patient_id': p.patient_id,
        'name': p.name,
        'age': p.age
    } for p in patients])

@app.route('/api/diagnose', methods=['POST'])
@jwt_required()
def diagnose():
    """ä¸Šä¼  DICOM å¹¶è¯Šæ–­"""
    file = request.files['file']
    patient_id = request.form.get('patient_id')
    
    # ä¿å­˜æ–‡ä»¶
    file_hash = hashlib.sha256(file.read()).hexdigest()
    file.seek(0)
    file_path = f'uploads/{file_hash}.dcm'
    file.save(file_path)
    
    # æ¨¡å‹æ¨ç†
    from core.predict import predict_dicom
    mask, metrics = predict_dicom(file_path)
    
    # ä¿å­˜è¯Šæ–­ç»“æœ
    diagnosis = Diagnosis(
        patient_id=patient_id,
        dice_score=metrics['dice'],
        mask_path=f'results/{file_hash}_mask.png',
        diagnosis_time=datetime.now()
    )
    db.session.add(diagnosis)
    db.session.commit()
    
    return jsonify({
        'diagnosis_id': diagnosis.id,
        'metrics': metrics,
        'mask_url': f'/api/results/{file_hash}_mask.png'
    })

@app.route('/api/diagnoses/history/<int:patient_id>', methods=['GET'])
@jwt_required()
def get_diagnosis_history(patient_id):
    """è·å–æ‚£è€…è¯Šæ–­å†å²"""
    diagnoses = Diagnosis.query.filter_by(patient_id=patient_id).order_by(Diagnosis.diagnosis_time.desc()).all()
    
    return jsonify([{
        'id': d.id,
        'dice_score': d.dice_score,
        'diagnosis_time': d.diagnosis_time.isoformat(),
        'mask_url': f'/api/results/{d.mask_path}'
    } for d in diagnoses])

@app.route('/api/compare', methods=['POST'])
def compare_diagnoses():
    """å¯¹æ¯”å¤šæ¬¡è¯Šæ–­ç»“æœ"""
    diagnosis_ids = request.json['diagnosis_ids']
    
    diagnoses = Diagnosis.query.filter(Diagnosis.id.in_(diagnosis_ids)).all()
    
    comparison = {
        'diagnoses': [{
            'id': d.id,
            'date': d.diagnosis_time.isoformat(),
            'dice': d.dice_score,
            'mask_url': d.mask_path
        } for d in diagnoses],
        'trend': analyze_trend([d.dice_score for d in diagnoses])
    }
    
    return jsonify(comparison)
```

### 4.3 å‰ç«¯åŠŸèƒ½æ‰©å±• (Vue)

```vue
<!-- CTAI_web/src/views/Dashboard.vue -->
<template>
  <div class="dashboard">
    <!-- ç»Ÿè®¡å¡ç‰‡ -->
    <el-row :gutter="20">
      <el-col :span="6">
        <el-card>
          <div class="stat-card">
            <i class="el-icon-user"></i>
            <div>
              <h3>{{ stats.totalPatients }}</h3>
              <p>æ€»æ‚£è€…æ•°</p>
            </div>
          </div>
        </el-card>
      </el-col>
      <el-col :span="6">
        <el-card>
          <div class="stat-card">
            <i class="el-icon-document"></i>
            <div>
              <h3>{{ stats.totalDiagnoses }}</h3>
              <p>è¯Šæ–­è®°å½•</p>
            </div>
          </div>
        </el-card>
      </el-col>
      <el-col :span="6">
        <el-card>
          <div class="stat-card">
            <i class="el-icon-success"></i>
            <div>
              <h3>{{ stats.avgDice }}%</h3>
              <p>å¹³å‡ Dice åˆ†æ•°</p>
            </div>
          </div>
        </el-card>
      </el-col>
    </el-row>

    <!-- æ‚£è€…åˆ—è¡¨ -->
    <el-card class="patient-list">
      <div slot="header">
        <span>æ‚£è€…åˆ—è¡¨</span>
        <el-button style="float: right" type="primary" @click="showAddPatient">
          æ·»åŠ æ‚£è€…
        </el-button>
      </div>
      <el-table :data="patients" stripe>
        <el-table-column prop="patient_id" label="æ‚£è€…ID"></el-table-column>
        <el-table-column prop="name" label="å§“å"></el-table-column>
        <el-table-column prop="age" label="å¹´é¾„"></el-table-column>
        <el-table-column label="æ“ä½œ">
          <template slot-scope="scope">
            <el-button size="small" @click="viewHistory(scope.row)">
              æŸ¥çœ‹å†å²
            </el-button>
            <el-button size="small" type="primary" @click="diagnose(scope.row)">
              æ–°è¯Šæ–­
            </el-button>
          </template>
        </el-table-column>
      </el-table>
    </el-card>

    <!-- è¯Šæ–­å¯¹è¯æ¡† -->
    <el-dialog title="æ–°è¯Šæ–­" :visible.sync="diagnosisDialog">
      <el-upload
        drag
        action="/api/diagnose"
        :headers="uploadHeaders"
        :on-success="onUploadSuccess"
        :data="{ patient_id: currentPatient.id }">
        <i class="el-icon-upload"></i>
        <div class="el-upload__text">æ‹–æ‹½ DICOM æ–‡ä»¶åˆ°æ­¤æˆ–<em>ç‚¹å‡»ä¸Šä¼ </em></div>
      </el-upload>
    </el-dialog>

    <!-- ç»“æœå±•ç¤º -->
    <el-dialog title="è¯Šæ–­ç»“æœ" :visible.sync="resultDialog" width="80%">
      <el-row :gutter="20">
        <el-col :span="12">
          <h4>åŸå§‹å›¾åƒ</h4>
          <img :src="result.originalImage" style="width: 100%">
        </el-col>
        <el-col :span="12">
          <h4>åˆ†å‰²ç»“æœ</h4>
          <img :src="result.maskImage" style="width: 100%">
        </el-col>
      </el-row>
      
      <el-divider></el-divider>
      
      <h4>è¯„ä¼°æŒ‡æ ‡</h4>
      <el-row :gutter="20">
        <el-col :span="6">
          <el-statistic title="Dice ç³»æ•°" :value="result.dice" :precision="4"></el-statistic>
        </el-col>
        <el-col :span="6">
          <el-statistic title="IoU" :value="result.iou" :precision="4"></el-statistic>
        </el-col>
        <el-col :span="6">
          <el-statistic title="çµæ•åº¦" :value="result.sensitivity" :precision="4"></el-statistic>
        </el-col>
        <el-col :span="6">
          <el-statistic title="ç‰¹å¼‚åº¦" :value="result.specificity" :precision="4"></el-statistic>
        </el-col>
      </el-row>
    </el-dialog>

    <!-- å†å²å¯¹æ¯” -->
    <el-dialog title="è¯Šæ–­å†å²å¯¹æ¯”" :visible.sync="historyDialog" width="90%">
      <el-timeline>
        <el-timeline-item
          v-for="item in history"
          :key="item.id"
          :timestamp="item.date">
          <el-card>
            <h4>Dice: {{ item.dice }}</h4>
            <img :src="item.maskUrl" style="width: 200px">
          </el-card>
        </el-timeline-item>
      </el-timeline>
      
      <!-- è¶‹åŠ¿å›¾ -->
      <div id="trendChart" style="height: 300px"></div>
    </el-dialog>
  </div>
</template>

<script>
import * as echarts from 'echarts'

export default {
  data() {
    return {
      stats: {},
      patients: [],
      diagnosisDialog: false,
      resultDialog: false,
      historyDialog: false,
      currentPatient: {},
      result: {},
      history: []
    }
  },
  mounted() {
    this.loadStats()
    this.loadPatients()
  },
  methods: {
    async loadStats() {
      const res = await this.$http.get('/api/stats')
      this.stats = res.data
    },
    
    async loadPatients() {
      const res = await this.$http.get('/api/patients')
      this.patients = res.data
    },
    
    diagnose(patient) {
      this.currentPatient = patient
      this.diagnosisDialog = true
    },
    
    onUploadSuccess(response) {
      this.diagnosisDialog = false
      this.result = response
      this.resultDialog = true
    },
    
    async viewHistory(patient) {
      const res = await this.$http.get(`/api/diagnoses/history/${patient.id}`)
      this.history = res.data
      this.historyDialog = true
      
      this.$nextTick(() => {
        this.renderTrendChart()
      })
    },
    
    renderTrendChart() {
      const chart = echarts.init(document.getElementById('trendChart'))
      chart.setOption({
        title: { text: 'Dice ç³»æ•°è¶‹åŠ¿' },
        xAxis: {
          type: 'category',
          data: this.history.map(h => h.date)
        },
        yAxis: { type: 'value', min: 0, max: 1 },
        series: [{
          data: this.history.map(h => h.dice),
          type: 'line',
          smooth: true
        }]
      })
    }
  }
}
</script>
```

---

## äº”ã€å¯è§†åŒ–ä¼˜åŒ–

### 5.1 3D å¯è§†åŒ– (å¯é€‰)

```python
# CTAI_flask/core/visualization.py
import numpy as np
import plotly.graph_objects as go

def create_3d_visualization(dicom_series, mask_series):
    """åˆ›å»º 3D è‚¿ç˜¤å¯è§†åŒ–"""
    # dicom_series: (Z, H, W) - å¤šä¸ªåˆ‡ç‰‡
    # mask_series: (Z, H, W) - å¯¹åº”çš„ mask
    
    # æå–è‚¿ç˜¤è¡¨é¢
    from skimage import measure
    verts, faces, _, _ = measure.marching_cubes(mask_series, level=0.5)
    
    # åˆ›å»º 3D mesh
    fig = go.Figure(data=[
        go.Mesh3d(
            x=verts[:, 0],
            y=verts[:, 1],
            z=verts[:, 2],
            i=faces[:, 0],
            j=faces[:, 1],
            k=faces[:, 2],
            color='red',
            opacity=0.5,
            name='è‚¿ç˜¤'
        )
    ])
    
    fig.update_layout(
        title='ç›´è‚ è‚¿ç˜¤ 3D é‡å»º',
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z'
        )
    )
    
    return fig.to_html()
```

### 5.2 çƒ­åŠ›å›¾å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_attention_map(image, attention_weights, save_path):
    """å¯è§†åŒ–æ³¨æ„åŠ›çƒ­åŠ›å›¾"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # åŸå›¾
    axes[0].imshow(image, cmap='gray')
    axes[0].set_title('åŸå§‹å›¾åƒ')
    axes[0].axis('off')
    
    # æ³¨æ„åŠ›çƒ­åŠ›å›¾
    axes[1].imshow(attention_weights, cmap='jet', alpha=0.6)
    axes[1].set_title('æ³¨æ„åŠ›çƒ­åŠ›å›¾')
    axes[1].axis('off')
    
    # å åŠ 
    axes[2].imshow(image, cmap='gray')
    axes[2].imshow(attention_weights, cmap='jet', alpha=0.4)
    axes[2].set_title('æ³¨æ„åŠ›å åŠ ')
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
```

### 5.3 å¯¹æ¯”å¯è§†åŒ–

```python
def create_comparison_visualization(original, ground_truth, prediction, save_path):
    """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # ç¬¬ä¸€è¡Œ
    axes[0, 0].imshow(original, cmap='gray')
    axes[0, 0].set_title('åŸå§‹å›¾åƒ')
    
    axes[0, 1].imshow(ground_truth, cmap='Reds', alpha=0.5)
    axes[0, 1].imshow(original, cmap='gray', alpha=0.5)
    axes[0, 1].set_title('çœŸå®æ ‡æ³¨')
    
    axes[0, 2].imshow(prediction, cmap='Blues', alpha=0.5)
    axes[0, 2].imshow(original, cmap='gray', alpha=0.5)
    axes[0, 2].set_title('æ¨¡å‹é¢„æµ‹')
    
    # ç¬¬äºŒè¡Œ - å·®å¼‚åˆ†æ
    tp = prediction * ground_truth
    fp = prediction * (1 - ground_truth)
    fn = (1 - prediction) * ground_truth
    
    diff_map = np.zeros((*original.shape, 3))
    diff_map[..., 1] = tp  # ç»¿è‰² - æ­£ç¡®é¢„æµ‹
    diff_map[..., 0] = fp  # çº¢è‰² - å‡é˜³æ€§
    diff_map[..., 2] = fn  # è“è‰² - å‡é˜´æ€§
    
    axes[1, 0].imshow(diff_map)
    axes[1, 0].set_title('å·®å¼‚åˆ†æ\n(ç»¿:TP çº¢:FP è“:FN)')
    
    # è½®å»“å¯¹æ¯”
    from skimage import measure
    contours_gt = measure.find_contours(ground_truth, 0.5)
    contours_pred = measure.find_contours(prediction, 0.5)
    
    axes[1, 1].imshow(original, cmap='gray')
    for contour in contours_gt:
        axes[1, 1].plot(contour[:, 1], contour[:, 0], 'r-', linewidth=2, label='çœŸå®')
    for contour in contours_pred:
        axes[1, 1].plot(contour[:, 1], contour[:, 0], 'b--', linewidth=2, label='é¢„æµ‹')
    axes[1, 1].set_title('è½®å»“å¯¹æ¯”')
    axes[1, 1].legend()
    
    # æŒ‡æ ‡å±•ç¤º
    from utils.metrics import MedicalMetrics
    metrics = MedicalMetrics()
    dice = metrics.dice_coefficient(prediction, ground_truth)
    iou = metrics.iou(prediction, ground_truth)
    sensitivity = metrics.sensitivity(prediction, ground_truth)
    specificity = metrics.specificity(prediction, ground_truth)
    
    axes[1, 2].axis('off')
    axes[1, 2].text(0.1, 0.8, f'Dice: {dice:.4f}', fontsize=14)
    axes[1, 2].text(0.1, 0.6, f'IoU: {iou:.4f}', fontsize=14)
    axes[1, 2].text(0.1, 0.4, f'çµæ•åº¦: {sensitivity:.4f}', fontsize=14)
    axes[1, 2].text(0.1, 0.2, f'ç‰¹å¼‚åº¦: {specificity:.4f}', fontsize=14)
    axes[1, 2].set_title('è¯„ä¼°æŒ‡æ ‡')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
```

---

## å…­ã€éƒ¨ç½²æ–¹æ¡ˆ

### 6.1 Docker å®¹å™¨åŒ–

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY CTAI_flask/ ./CTAI_flask/
COPY CTAI_model/ ./CTAI_model/

# æš´éœ²ç«¯å£
EXPOSE 5000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "CTAI_flask/app.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  # MySQL æ•°æ®åº“
  db:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: ctai_db
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # åç«¯ API
  backend:
    build: .
    ports:
      - "5000:5000"
    depends_on:
      - db
      - redis
    environment:
      DATABASE_URL: mysql://root:rootpassword@db:3306/ctai_db
      REDIS_URL: redis://redis:6379
    volumes:
      - ./uploads:/app/uploads
      - ./models:/app/models

  # å‰ç«¯ Nginx
  frontend:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./CTAI_web/dist:/usr/share/nginx/html
      - ./nginx.conf:/etc/nginx/nginx.conf

volumes:
  mysql_data:
```

### 6.2 æ€§èƒ½ä¼˜åŒ–

```python
# CTAI_flask/core/model_cache.py
from functools import lru_cache
import redis

# Redis ç¼“å­˜
redis_client = redis.Redis(host='localhost', port=6379, db=0)

@lru_cache(maxsize=1)
def load_model():
    """å•ä¾‹æ¨¡å¼åŠ è½½æ¨¡å‹ (é¿å…é‡å¤åŠ è½½)"""
    import torch
    from net.transunet import TransUNet
    
    model = TransUNet()
    model.load_state_dict(torch.load('models/transunet_best.pth'))
    model.eval()
    model.to('cuda' if torch.cuda.is_available() else 'cpu')
    
    return model

def predict_with_cache(image_hash, image_data):
    """ä½¿ç”¨ Redis ç¼“å­˜é¢„æµ‹ç»“æœ"""
    # æ£€æŸ¥ç¼“å­˜
    cached_result = redis_client.get(f'pred:{image_hash}')
    if cached_result:
        return json.loads(cached_result)
    
    # æ‰§è¡Œé¢„æµ‹
    model = load_model()
    result = model.predict(image_data)
    
    # å­˜å…¥ç¼“å­˜ (24å°æ—¶è¿‡æœŸ)
    redis_client.setex(
        f'pred:{image_hash}',
        86400,
        json.dumps(result)
    )
    
    return result
```

---

## ä¸ƒã€è®ºæ–‡æ’°å†™æŒ‡å¯¼

### 7.1 è®ºæ–‡ç»“æ„

```markdown
# åŸºäº Transformer-UNet èåˆçš„ç›´è‚ è‚¿ç˜¤ CT å›¾åƒæ™ºèƒ½åˆ†å‰²ç³»ç»Ÿ

## æ‘˜è¦
- ç ”ç©¶èƒŒæ™¯å’Œæ„ä¹‰
- ä¸»è¦å·¥ä½œå’Œè´¡çŒ®
- å®éªŒç»“æœ (Dice ç³»æ•°ç­‰)
- ç»“è®º

## ç¬¬ä¸€ç«  ç»ªè®º
1.1 ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰
1.2 å›½å†…å¤–ç ”ç©¶ç°çŠ¶
    - åŒ»å­¦å›¾åƒåˆ†å‰²ç»¼è¿°
    - UNet ç³»åˆ—æ–¹æ³•
    - Transformer åœ¨åŒ»å­¦å›¾åƒä¸­çš„åº”ç”¨
1.3 æœ¬æ–‡ä¸»è¦å·¥ä½œ
1.4 è®ºæ–‡ç»„ç»‡ç»“æ„

## ç¬¬äºŒç«  ç›¸å…³æŠ€æœ¯ä¸ç†è®ºåŸºç¡€
2.1 åŒ»å­¦å›¾åƒåˆ†å‰²æ¦‚è¿°
2.2 å·ç§¯ç¥ç»ç½‘ç»œ (CNN)
    - å·ç§¯å±‚ã€æ± åŒ–å±‚
    - U-Net æ¶æ„è¯¦è§£
2.3 æ³¨æ„åŠ›æœºåˆ¶
    - Attention Gate
    - Self-Attention
2.4 Transformer
    - Multi-Head Attention
    - Position Encoding
2.5 è¯„ä¼°æŒ‡æ ‡
    - Dice ç³»æ•°
    - IoU
    - çµæ•åº¦/ç‰¹å¼‚åº¦

## ç¬¬ä¸‰ç«  TransUNet æ¨¡å‹è®¾è®¡
3.1 æ•´ä½“æ¶æ„è®¾è®¡
3.2 Transformer Encoder
    - Patch Embedding
    - Multi-Head Self-Attention
    - Feed-Forward Network
3.3 CNN Decoder
    - ä¸Šé‡‡æ ·æ¨¡å—
    - Skip Connection
    - Attention Gate
3.4 æŸå¤±å‡½æ•°è®¾è®¡
    - Dice Loss
    - BCE Loss
    - ç»„åˆæŸå¤±å‡½æ•°

## ç¬¬å››ç«  å®éªŒä¸ç»“æœåˆ†æ
4.1 æ•°æ®é›†ä»‹ç»
    - æ•°æ®æ¥æº
    - æ•°æ®é¢„å¤„ç†
    - æ•°æ®å¢å¼º
4.2 å®éªŒç¯å¢ƒä¸å‚æ•°è®¾ç½®
    - ç¡¬ä»¶ç¯å¢ƒ
    - è¶…å‚æ•°é…ç½®
4.3 å®éªŒç»“æœ
    - å®šé‡è¯„ä¼° (Dice, IoU, etc.)
    - å®šæ€§è¯„ä¼° (å¯è§†åŒ–å¯¹æ¯”)
    - æ¶ˆèå®éªŒ (éªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§)
4.4 ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”
    - UNet
    - Attention UNet
    - UNet++
    - TransUNet (æœ¬æ–‡)

## ç¬¬äº”ç«  ç³»ç»Ÿè®¾è®¡ä¸å®ç°
5.1 ç³»ç»Ÿæ€»ä½“æ¶æ„
5.2 æ•°æ®åº“è®¾è®¡
5.3 åç«¯è®¾è®¡
    - API æ¥å£
    - æ¨¡å‹æ¨ç†
5.4 å‰ç«¯è®¾è®¡
    - ç”¨æˆ·ç•Œé¢
    - å¯è§†åŒ–å±•ç¤º
5.5 ç³»ç»Ÿæµ‹è¯•

## ç¬¬å…­ç«  æ€»ç»“ä¸å±•æœ›
6.1 å·¥ä½œæ€»ç»“
6.2 åˆ›æ–°ç‚¹
6.3 ä¸è¶³ä¸å±•æœ›

å‚è€ƒæ–‡çŒ®
è‡´è°¢
é™„å½• (ä»£ç ã€æ•°æ®é›†è¯´æ˜)
```

### 7.2 å…³é”®å®éªŒå¯¹æ¯”è¡¨

```markdown
## æ¶ˆèå®éªŒ (åŸºäºæ–°6:2:2æ•°æ®åˆ’åˆ†)

| æ¨¡å‹ | è®­ç»ƒDice | éªŒè¯Dice | æµ‹è¯•Dice â†‘ | å‚æ•°é‡ | è¯´æ˜ |
|------|---------|---------|-----------|--------|------|
| UNet(æ—§,æ•°æ®æ³„éœ²) | 92.57% | - | 85.42% | 31.5M | âŒ è™šé«˜,æœ‰æ•°æ®æ³„éœ² |
| **UNet(æ–°,æ— æ³„éœ²)** | **87.81%** | **75.11%** | **78.02%** | **31.39M** | âœ… **çœŸå®åŸºçº¿** |
| TransUNet (å¾…è®­ç»ƒ) | - | - | 83-88% (é¢„æœŸ) | 93.42M | ğŸ¯ ç›®æ ‡ |
| TransUNetLite (å¯é€‰) | - | - | 80-84% (é¢„æœŸ) | 14.11M | è½»é‡ç‰ˆ |

## å…³é”®å‘ç°

**æ•°æ®æ³„éœ²å½±å“:** ä¿®å¤åæ€§èƒ½ä»85.42%é™è‡³78.02% (**-7.4%**)  
**é¡ºåºåå·®å½±å“:** éšæœºåˆ’åˆ†æ¯”é¡ºåºåˆ’åˆ†é«˜ **+21.67%** (56.35%â†’78.02%)  
**çœŸå®åŸºçº¿ç¡®ç«‹:** 78.02% æ˜¯å¯ä¿¡çš„æ³›åŒ–æ€§èƒ½
```

---

## å…«ã€æ—¶é—´è§„åˆ’

### 8.1 å¼€å‘é˜¶æ®µ (å»ºè®® 2-3 ä¸ªæœˆ)

#### **ç¬¬ 1-2 å‘¨ï¼šæ¨¡å‹å¼€å‘**
- [ ] å®ç° TransUNet æ¶æ„
- [ ] è¿ç§» ViT é¢„è®­ç»ƒæƒé‡
- [ ] æ·»åŠ æ•°æ®å¢å¼º

#### **ç¬¬ 3-4 å‘¨ï¼šè®­ç»ƒä¼˜åŒ–**
- [ ] å­¦ä¹ ç‡è°ƒåº¦
- [ ] æ··åˆç²¾åº¦è®­ç»ƒ
- [ ] æ¶ˆèå®éªŒ

#### **ç¬¬ 5-6 å‘¨ï¼šç³»ç»Ÿåç«¯**
- [ ] æ•°æ®åº“è®¾è®¡
- [ ] API å¼€å‘
- [ ] æ¨¡å‹éƒ¨ç½²

#### **ç¬¬ 7-8 å‘¨ï¼šç³»ç»Ÿå‰ç«¯**
- [ ] ç•Œé¢è®¾è®¡
- [ ] å¯è§†åŒ–åŠŸèƒ½
- [ ] å†å²å¯¹æ¯”

#### **ç¬¬ 9-10 å‘¨ï¼šæµ‹è¯•ä¸ä¼˜åŒ–**
- [ ] ç³»ç»Ÿæµ‹è¯•
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] Bug ä¿®å¤

#### **ç¬¬ 11-12 å‘¨ï¼šæ–‡æ¡£ä¸éƒ¨ç½²**
- [ ] æ’°å†™è®ºæ–‡
- [ ] Docker éƒ¨ç½²
- [ ] ç”¨æˆ·æ‰‹å†Œ

### 8.2 è®ºæ–‡æ’°å†™ (ä¸å¼€å‘å¹¶è¡Œ)

#### **é˜¶æ®µ 1ï¼šæ–‡çŒ®è°ƒç ” (1-2 å‘¨)**
- é˜…è¯» 30-50 ç¯‡ç›¸å…³è®ºæ–‡
- æ•´ç†ç»¼è¿°éƒ¨åˆ†

#### **é˜¶æ®µ 2ï¼šå®éªŒè®°å½• (å¼€å‘æœŸé—´)**
- è®°å½•æ¯æ¬¡å®éªŒç»“æœ
- ä¿å­˜å¯è§†åŒ–å›¾è¡¨
- æ•´ç†å¯¹æ¯”æ•°æ®

#### **é˜¶æ®µ 3ï¼šè®ºæ–‡æ’°å†™ (2-3 å‘¨)**
- å®Œæˆåˆç¨¿
- å¯¼å¸ˆå®¡é˜…
- ä¿®æ”¹å®Œå–„

#### **é˜¶æ®µ 4ï¼šç­”è¾©å‡†å¤‡ (1 å‘¨)**
- åˆ¶ä½œ PPT
- å‡†å¤‡æ¼”ç¤º Demo
- é¢„ç­”è¾©

---

## ä¹ã€é¢„æœŸæˆæœ

### 9.1 æŠ€æœ¯æŒ‡æ ‡
- **Dice ç³»æ•°**: > 0.78 (ç›®æ ‡ 0.80+)
- **IoU**: > 0.70
- **çµæ•åº¦**: > 0.80
- **ç‰¹å¼‚åº¦**: > 0.97
- **æ¨ç†é€Ÿåº¦**: < 150ms/å¼ 

### 9.2 åˆ›æ–°ç‚¹
1. **æ¶æ„åˆ›æ–°**: Transformer + UNet èåˆï¼Œå…¼é¡¾å…¨å±€å’Œå±€éƒ¨ç‰¹å¾
2. **æ³¨æ„åŠ›æœºåˆ¶**: åŒé‡æ³¨æ„åŠ› (ç©ºé—´ + é€šé“)
3. **æŸå¤±å‡½æ•°**: Dice Loss + BCE Loss ç»„åˆ
4. **ç³»ç»Ÿå®Œæ•´**: å‰åç«¯åˆ†ç¦»ï¼Œæ•°æ®åº“ç®¡ç†ï¼Œå¯è§†åŒ–å±•ç¤º

### 9.3 è®ºæ–‡å‘è¡¨æ½œåŠ›
- **ä¼šè®®**: ISBI, MICCAI (åŒ»å­¦å›¾åƒé¡¶ä¼š)
- **æœŸåˆŠ**: Medical Image Analysis, IEEE TMI
- **ä¸­æ–‡æœŸåˆŠ**: è®¡ç®—æœºå­¦æŠ¥ã€è½¯ä»¶å­¦æŠ¥

---

## åã€é£é™©ä¸å¯¹ç­–

### 10.1 å¯èƒ½é‡åˆ°çš„é—®é¢˜

#### **é—®é¢˜ 1ï¼šTransformer æ˜¾å­˜ä¸è¶³**
**å¯¹ç­–ï¼š**
- ä½¿ç”¨ ViT-Small è€Œé ViT-Base
- æ¢¯åº¦ç´¯ç§¯
- æ··åˆç²¾åº¦è®­ç»ƒ

#### **é—®é¢˜ 2ï¼šè®­ç»ƒæ—¶é—´è¿‡é•¿**
**å¯¹ç­–ï¼š**
- ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
- å‡å°‘ Transformer å±‚æ•° (12 â†’ 6)
- åˆ†å¸ƒå¼è®­ç»ƒ (å¦‚æœ‰å¤šå¡)

#### **é—®é¢˜ 3ï¼šæ€§èƒ½æå‡ä¸æ˜æ˜¾**
**å¯¹ç­–ï¼š**
- è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡
- å¢åŠ æ•°æ®å¢å¼º
- å°è¯•ä¸åŒçš„ Transformer é…ç½®

#### **é—®é¢˜ 4ï¼šå‰ç«¯å¼€å‘å›°éš¾**
**å¯¹ç­–ï¼š**
- ä½¿ç”¨ç°æˆ UI æ¨¡æ¿
- ç®€åŒ–åŠŸèƒ½ï¼Œèšç„¦æ ¸å¿ƒ
- å¯»æ±‚å‰ç«¯åŒå­¦ååŠ©

---

## åä¸€ã€å‚è€ƒèµ„æº

### 11.1 è®ºæ–‡
1. **UNet**: *U-Net: Convolutional Networks for Biomedical Image Segmentation* (MICCAI 2015)
2. **Attention UNet**: *Attention U-Net: Learning Where to Look for the Pancreas* (MIDL 2018)
3. **TransUNet**: *TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation* (2021)
4. **ViT**: *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale* (ICLR 2021)

### 11.2 ä»£ç å‚è€ƒ
- **TransUNet å®˜æ–¹**: https://github.com/Beckschen/TransUNet
- **timm åº“**: https://github.com/rwightman/pytorch-image-models
- **åŒ»å­¦å›¾åƒåˆ†å‰²å·¥å…·**: https://github.com/MIC-DKFZ/nnUNet

### 11.3 æ•°æ®é›†
- **æœ¬é¡¹ç›®æ•°æ®é›†**: 107 æ‚£è€…ç›´è‚  CT
- **å…¬å¼€æ•°æ®é›†** (å¯å¯¹æ¯”):
  - ACDC (å¿ƒè„åˆ†å‰²)
  - Synapse (å¤šå™¨å®˜åˆ†å‰²)

---

## åäºŒã€è”ç³»ä¸æ”¯æŒ

### 12.1 æŠ€æœ¯æ ˆ
- **æ·±åº¦å­¦ä¹ **: PyTorch 1.10+
- **åç«¯**: Flask / Spring Boot (å¯é€‰)
- **å‰ç«¯**: Vue 2.6 + Element UI
- **æ•°æ®åº“**: MySQL 8.0
- **éƒ¨ç½²**: Docker + Nginx

### 12.2 ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA RTX 3050+ (4GB+ VRAM)
- **CPU**: 4 æ ¸+
- **å†…å­˜**: 16GB+
- **å­˜å‚¨**: 50GB+

---

## æ€»ç»“

è¿™ä»½ä¼˜åŒ–æ–¹æ¡ˆæ¶µç›–äº†ä»**æ¨¡å‹åˆ›æ–°**åˆ°**ç³»ç»Ÿå®Œå–„**ï¼Œå†åˆ°**è®ºæ–‡æ’°å†™**çš„å…¨æµç¨‹ã€‚æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ **TransUNet æ¶æ„**ï¼Œç»“åˆå®Œæ•´çš„è¯Šæ–­ç³»ç»Ÿï¼Œè¶³ä»¥æ”¯æ’‘ä¸€ç¯‡ä¼˜ç§€çš„æ¯•ä¸šè®¾è®¡ã€‚

**å…³é”®å»ºè®®ï¼š**
1. **èšç„¦æ ¸å¿ƒ**: TransUNet æ¨¡å‹æ˜¯æœ€å¤§äº®ç‚¹ï¼ŒåŠ¡å¿…åšå¥½
2. **é€æ­¥æ¨è¿›**: å…ˆæ¨¡å‹åç³»ç»Ÿï¼Œé¿å…æˆ˜çº¿è¿‡é•¿
3. **è®°å½•è¯¦ç»†**: æ¯æ¬¡å®éªŒéƒ½è®°å½•ï¼Œä¸ºè®ºæ–‡ç§¯ç´¯ç´ æ
4. **å¯»æ±‚æŒ‡å¯¼**: é‡åˆ°é—®é¢˜åŠæ—¶è¯·æ•™å¯¼å¸ˆæˆ–æŸ¥é˜…æ–‡çŒ®

**é¢„æœŸæˆæœï¼š**
- Dice 80%+ çš„é«˜æ€§èƒ½æ¨¡å‹
- å®Œæ•´çš„è¯Šæ–­ç³»ç»Ÿ
- ä¸€ç¯‡ä¼˜ç§€çš„æ¯•ä¸šè®ºæ–‡
- æ½œåœ¨çš„è®ºæ–‡å‘è¡¨æœºä¼š

**ç¥ä½ æ¯•ä¸šè®¾è®¡é¡ºåˆ©ï¼** ğŸ“ğŸš€
